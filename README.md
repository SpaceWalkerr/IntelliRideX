# ğŸš— Deep Learning-Based Computer Vision for Autonomous Vehicles

> An interactive research platform exploring cutting-edge deep learning architectures for autonomous vehicle perception systems

[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB)](https://reactjs.org/)
[![Vite](https://img.shields.io/badge/Vite-646CFF?style=for-the-badge&logo=vite&logoColor=white)](https://vitejs.dev/)
[![TailwindCSS](https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white)](https://tailwindcss.com/)

---

## ğŸ“– Overview

This project presents a comprehensive, interactive research platform for exploring deep learning-based computer vision techniques in autonomous vehicles. It combines theoretical knowledge with practical simulations, allowing users to experiment with different architectures, datasets, and environmental conditions.

### ğŸ¯ Key Objectives

- **Education**: Make complex CV/DL concepts accessible through interactive visualizations
- **Research**: Compare performance of CNN, PointNet, and Transformer architectures
- **Experimentation**: Real-time simulation of detection scenarios across weather conditions
- **Analysis**: Deep insights into model trade-offs, error patterns, and performance metrics

---

## âœ¨ Features

### ğŸ  Home & Techniques
- **Hero Section** with animated neural network visualization
- **Research Pipeline** walkthrough (data collection â†’ preprocessing â†’ training â†’ deployment)
- **Interactive Techniques Cards** covering:
  - Object Detection (YOLO, R-CNN, SSD)
  - Semantic Segmentation (U-Net, DeepLab, PSPNet)
  - 3D Object Detection (PointNet, PointPillars, VoxelNet)
  - Multi-Task Learning & Sensor Fusion

### ğŸ—‚ï¸ Datasets Page
- **Interactive Dataset Cards** with flip animations (KITTI, Waymo, nuScenes, BDD100K)
- **Live Comparison Table** â€” adjust parameters (accuracy, FPS, sensor config, weather coverage) and see immediate results
- **Real-time Detection Preview** â€” SVG-based urban scene with:
  - Dynamic vehicles (cars, trucks, pedestrians, cyclists)
  - Environmental effects (night mode, noise, motion blur)
  - Bounding boxes with confidence scores
- **Try Your Own Method** â€” custom model input with radar chart comparison against baselines

### ğŸ“Š Results Dashboard
- **KPI Cards** â€” Animated metrics (Accuracy, FPS, Loss, Precision, Recall)
- **Visual Output Panel** ğŸ”¥ â€” Premium slider-based before/after comparison:
  - ğŸš— Object Detection mode
  - ğŸ›£ï¸ Semantic Segmentation mode
  - ğŸš¦ Lane Detection mode
- **Model Performance Charts** â€” Bar & line charts comparing architectures
- **Real-Time Simulation** â€” Control panel with live metric updates:
  - Model selector (CNN/PointNet/Transformer)
  - Dataset selector (KITTI/Waymo/nuScenes)
  - Scenario testing (Clear/Rain/Fog/Night)
- **Error Analysis** â€” False positive/negative breakdown
- **Trade-off Visualization** â€” Accuracy vs. Speed scatter plot
- **AI Insights Generator** â€” Auto-generated key takeaways

---

## ğŸ› ï¸ Tech Stack

### Frontend Framework
- **React 18** â€” Component-based architecture
- **TypeScript** â€” Type-safe development
- **Vite** â€” Lightning-fast dev server and build tool

### Styling & UI
- **Tailwind CSS** â€” Utility-first styling
- **shadcn/ui** â€” Beautiful, accessible component library
- **Radix UI** â€” Headless UI primitives
- **Framer Motion** â€” Smooth animations & transitions

### Data Visualization
- **Chart.js** â€” Interactive charts (Bar, Line, Radar)
- **react-chartjs-2** â€” React wrapper for Chart.js
- **Custom SVG** â€” Hand-crafted visualizations for maximum control

### State & Routing
- **React Router** â€” Client-side routing
- **TanStack Query** â€” Server state management (future API integration)
- **React Hooks** â€” Local state and effects

---

## ğŸš€ Getting Started

### Prerequisites
- **Node.js** >= 18.x
- **npm** or **yarn** or **pnpm**

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/autonomous-vehicle-cv-research.git
   cd autonomous-vehicle-cv-research
   ```

2. **Install dependencies**
   ```bash
   npm install
   # or
   yarn install
   # or
   pnpm install
   ```

3. **Start development server**
   ```bash
   npm run dev
   ```

4. **Open in browser**
   ```
   http://localhost:5173
   ```

### Build for Production

```bash
npm run build
npm run preview
```

---

## ğŸ“ Project Structure

```
research-project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # Reusable React components
â”‚   â”‚   â”œâ”€â”€ ui/              # shadcn/ui components
â”‚   â”‚   â”œâ”€â”€ Hero.tsx
â”‚   â”‚   â”œâ”€â”€ HeroBackground.tsx
â”‚   â”‚   â”œâ”€â”€ Navbar.tsx
â”‚   â”‚   â”œâ”€â”€ NeuralVisual.tsx
â”‚   â”‚   â”œâ”€â”€ PipelineSection.tsx
â”‚   â”‚   â””â”€â”€ TechniquesSection.tsx
â”‚   â”œâ”€â”€ pages/               # Route pages
â”‚   â”‚   â”œâ”€â”€ Index.tsx        # Home page
â”‚   â”‚   â”œâ”€â”€ TechniquesPage.tsx
â”‚   â”‚   â”œâ”€â”€ DatasetsPage.tsx
â”‚   â”‚   â”œâ”€â”€ ResultsPage.tsx  # Dashboard
â”‚   â”‚   â””â”€â”€ NotFound.tsx
â”‚   â”œâ”€â”€ hooks/               # Custom React hooks
â”‚   â”œâ”€â”€ lib/                 # Utility functions
â”‚   â”œâ”€â”€ App.tsx              # Root component
â”‚   â”œâ”€â”€ main.tsx             # Entry point
â”‚   â””â”€â”€ index.css            # Global styles
â”œâ”€â”€ public/                  # Static assets
â”œâ”€â”€ .gitignore
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ vite.config.ts
â””â”€â”€ README.md
```

---

## ğŸ¨ Design Philosophy

### Glassmorphism UI
- Semi-transparent cards with backdrop blur
- Subtle borders and shadows
- Dark theme optimized for readability

### Micro-interactions
- Smooth hover states
- Page transition animations
- Scroll-triggered reveals
- Interactive sliders and toggles

### Responsive Design
- Mobile-first approach
- Adaptive layouts (grid â†’ stack)
- Touch-friendly controls

---

## ğŸ“Š Datasets Covered

| Dataset | Frames | Sensors | Weather | Urban/Highway |
|---------|--------|---------|---------|---------------|
| **KITTI** | 15K | Camera + LiDAR | Clear â˜€ï¸ | Urban |
| **Waymo Open** | 230K | Multi-sensor | Multi-condition ğŸŒ§ï¸ | Both |
| **nuScenes** | 40K | Camera + Radar + LiDAR | Day/Night ğŸŒ™ | Urban |
| **BDD100K** | 100K | Camera | All weather â›ˆï¸ | Diverse |

---

## ğŸ§  Architectures Explored

### 1. CNN-based
- **YOLO** (v3-v8) â€” Real-time object detection
- **Faster R-CNN** â€” Two-stage detection
- **U-Net** â€” Semantic segmentation

### 2. Transformer-based
- **DETR** â€” End-to-end detection
- **Swin Transformer** â€” Hierarchical vision
- **SegFormer** â€” Efficient segmentation

### 3. Point Cloud
- **PointNet / PointNet++** â€” 3D feature learning
- **PointPillars** â€” Fast 3D detection
- **VoxelNet** â€” Voxel-based detection

---

## ğŸ”¬ Research Insights

### Key Findings (from Simulation)

1. **Accuracy vs Speed Trade-off**
   - Transformers achieve 91% accuracy but run at 18 FPS
   - CNNs balance speed (45 FPS) with 76% accuracy
   - PointNet offers middle ground (86% / 25 FPS)

2. **Dataset Impact**
   - Waymo's multi-sensor data improves accuracy by 8-15%
   - KITTI's smaller size enables faster training/inference
   - nuScenes excels in night/rain scenarios

3. **Error Patterns**
   - False positives peak in dense traffic (12%)
   - False negatives common for distant objects (16%)
   - Night conditions reduce accuracy by 15%

4. **Weather Robustness**
   - Rain: -8% accuracy penalty
   - Fog: -12% accuracy drop
   - Night: -15% with standard models

---

## ğŸ›£ï¸ Roadmap

### âœ… Completed
- [x] Home page with neural network visualization
- [x] Techniques overview page
- [x] Dataset comparison page with live simulation
- [x] Results dashboard with 8 analysis sections
- [x] Interactive slider-based before/after visualization
- [x] Real-time scenario testing

### ğŸš§ In Progress
- [ ] Architectures page (detailed model breakdowns)
- [ ] Challenges page (edge cases, adversarial examples)
- [ ] Future Scope page (trends, emerging tech)

### ğŸ”® Future Enhancements
- [ ] Backend integration (real model inference)
- [ ] Upload custom images for detection
- [ ] Export comparison reports (PDF/CSV)
- [ ] 3D visualization of point clouds
- [ ] Model training playground
- [ ] Community contributions (share custom models)

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Development Guidelines
- Use TypeScript for type safety
- Follow existing code style (ESLint configured)
- Add comments for complex logic
- Test across browsers (Chrome, Firefox, Safari)

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

### Datasets
- [KITTI Vision Benchmark](http://www.cvlibs.net/datasets/kitti/)
- [Waymo Open Dataset](https://waymo.com/open/)
- [nuScenes Dataset](https://www.nuscenes.org/)
- [BDD100K Dataset](https://bdd-data.berkeley.edu/)

### Inspirations
- YOLO (Redmon et al.)
- PointNet (Qi et al.)
- DETR (Carion et al.)
- Various computer vision research papers

### Tools & Libraries
- [shadcn/ui](https://ui.shadcn.com/) â€” Component library
- [Framer Motion](https://www.framer.com/motion/) â€” Animation library
- [Chart.js](https://www.chartjs.org/) â€” Charting library
- [Lucide Icons](https://lucide.dev/) â€” Icon set

---

## ğŸ“§ Contact

**Project Maintainer**: Suraj Nandan
**Email**: surajnandan782gmail.com
**GitHub**: [@SpaceWalkerr](https://github.com/SpaceWalkerr)

---

## ğŸŒŸ Star History

If you find this project useful, please consider giving it a star â­ï¸

---

<div align="center">
  <p>Built with â¤ï¸ for the autonomous vehicle research community</p>
  <p>Â© 2026 Deep Learning CV Research Project</p>
</div>
